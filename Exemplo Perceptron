import numpy as np

class Perceptron:
    """
    Implementação do classificador Perceptron de Rosenblatt.

    Parâmetros
    ----------
    eta : float
      Taxa de aprendizado (entre 0.0 e 1.0).
    n_iter : int
      Número de passagens sobre o conjunto de treinamento (épocas).
    random_state : int
      Semente para o gerador de números aleatórios para inicialização de pesos.

    Atributos
    ---------
    w_ : array-1d
      Pesos após o treinamento. w_[0] é o bias.
    errors_ : list
      Número de classificações incorretas (erros) em cada época.
    """
    def __init__(self, eta=0.01, n_iter=50, random_state=1):
        self.eta = eta
        self.n_iter = n_iter
        self.random_state = random_state

    def fit(self, X, y):
        """
        Ajusta o modelo aos dados de treinamento.

        Parâmetros
        ----------
        X : {array-like}, shape = [n_samples, n_features]
          Vetores de treinamento.
        y : array-like, shape = [n_samples]
          Valores alvo (rótulos). Usa-se 1 e -1.
        """
        rgen = np.random.RandomState(self.random_state)
        # Inicializa pesos com pequenos valores aleatórios, +1 para o bias
        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])
        self.errors_ = []

        for _ in range(self.n_iter):
            errors = 0
            for xi, target in zip(X, y):
                # Calcula a atualização dos pesos
                # update = eta * (target - predição)
                update = self.eta * (target - self.predict(xi))
                
                # Aplica a regra de atualização
                self.w_[1:] += update * xi  # Atualiza pesos das features
                self.w_[0] += update        # Atualiza o bias
                
                # Incrementa o contador de erros
                errors += int(update != 0.0)
            self.errors_.append(errors)
        return self

    def net_input(self, X):
        """Calcula a entrada líquida (soma ponderada)"""
        # z = w · x + b
        return np.dot(X, self.w_[1:]) + self.w_[0]

    def predict(self, X):
        """Retorna o rótulo da classe (1 ou -1) após a função degrau"""
        return np.where(self.net_input(X) >= 0.0, 1, -1)

# --- Exemplo de Uso (Problema AND, linearmente separável) ---
X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_and = np.array([-1, -1, -1, 1]) # Rótulos -1 (Falso) e 1 (Verdadeiro)

ppn = Perceptron(eta=0.1, n_iter=10)
ppn.fit(X_and, y_and)

print("--- Teste do Perceptron (Porta Lógica AND) ---")
print(f"Pesos finais: {ppn.w_}")
print(f"Erros por época: {ppn.errors_}")
print(f"Predições: {ppn.predict(X_and)}")
